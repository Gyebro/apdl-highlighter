<!DOCTYPE html><html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
   <meta name="date" content="2017-07-14 18:41:00-04:00"><title>14.7.&nbsp;Equation Solvers</title><link rel="stylesheet" type="text/css" href="basic.css"><meta name="generator" content="DocBook XSL Stylesheets V1.76.1"><link rel="home" href="ans_thry.html" title="Mechanical APDL Theory Reference"><link rel="up" href="thy_tool.html" title="Chapter&nbsp;14:&nbsp;Analysis Tools"><link rel="prev" href="thy_tool7.html" title="14.6.&nbsp;Solving for Unknowns and Reactions"><link rel="next" href="thy_tool9.html" title="14.8.&nbsp;Mode-Superposition Method"><script type="text/javascript"><!--
function toggleElementDisplay (id) {
  var elem = document.getElementById(id);
  if (elem.style.display != "block") {
    elem.style.display = "block";
  } else {
    elem.style.display = "none";
  }
}
//--></script></head><body bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF"><div class="sect1" title="14.7.&nbsp;Equation Solvers"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="OCiAf2a7lmm"></a>14.7.&nbsp;Equation Solvers</h2></div></div></div><p>The system of simultaneous linear equations generated by the
finite element procedure is solved either using a direct elimination
process or an iterative method. A direct elimination process is primarily
a Gaussian elimination approach which involves solving for the unknown
vector of variables {u} in <a class="xref" href="thy_tool8.html#thyeq1solversnov2101" title="(14&#8211;85)">Equation&nbsp;14&#8211;85</a>: </p><table width="100%" class="equation"><colgroup><col width="95%" align="center"><col width="5%" align="right"></colgroup><tr><td align="center"><a name="thyeq1solversnov2101"></a><div><img src="graphics/thyeq1solversnov2101.svg"></div></td><td nowrap="yes" align="right" valign="middle"><p class="title"><b>(14&#8211;85)</b></p></td></tr></table><p>where: </p><table border="0" summary="Simple list" class="simplelist"><tr><td>[K] = global stiffness/conductivity matrix </td></tr><tr><td>{u} = global vector of nodal unknown </td></tr><tr><td>{F} = global applied load vector </td></tr></table><p>
</p><p>The direct elimination process involves decomposition (factorization)
of the matrix [K] into lower and upper triangular matrices, [K] =
[L][U]. Then forward and back substitutions using [L] and [U] are
made to compute the solution vector {u}. </p><p>A typical iterative method involves an initial guess, {u}<sub>1</sub>, of the solution vector {u} and then a successive steps
of iteration leading to a sequence of vectors {u}<sub>2</sub>, {u}<sub>3</sub>, . . . such that, in the limit, {u}<sub>n</sub> = {u} as n tends to infinity. The calculation of {u}<sub>n + 1</sub> involves [K], {F}, and the {u} vectors from one
or two of the previous iterations. Typically the solution converges
to within a specified tolerance after a finite number of iterations. </p><p>In the following sections, all of the solvers are described
under two major subsections: Direct Solvers and Iterative Solvers
(all accessed with <a href="../ans_cmd/Hlp_C_EQSLV.html" class="olink"><span class="command"><strong>EQSLV</strong></span></a>).</p><div class="sect2" title="14.7.1.&nbsp;Direct Solvers"><div class="titlepage"><div><div><h3 class="title"><a name="eltdirectsol"></a>14.7.1.&nbsp;Direct Solvers</h3></div></div></div><a class="indexterm" name="d0e68649"></a><a class="indexterm" name="d0e68652"></a><p>The direct solver that is available is the Sparse Direct Solver
(accessed with <a href="../ans_cmd/Hlp_C_EQSLV.html" class="olink"><span class="command"><strong>EQSLV</strong></span></a>,SPARSE). The Sparse Direct
Solver makes use of the fact that the finite element matrices are
normally sparsely populated. This sparsity allows the system of simultaneous
equations to be solved efficiently by minimizing the operation counts.</p></div><div class="sect2" title="14.7.2.&nbsp;Sparse Direct Solver"><div class="titlepage"><div><div><h3 class="title"><a name="eltsparsesolv"></a>14.7.2.&nbsp;Sparse Direct Solver</h3></div></div></div><a class="indexterm" name="d0e68666"></a><a class="indexterm" name="d0e68669"></a><p>As described in the introductory section, the linear matrix
equation, (<a class="xref" href="thy_tool8.html#thyeq1solversnov2101" title="(14&#8211;85)">Equation&nbsp;14&#8211;85</a>) is solved by triangular
decomposition of matrix [K] to yield the following equation:</p><table width="100%" class="equation"><colgroup><col width="95%" align="center"><col width="5%" align="right"></colgroup><tr><td align="center"><a name="thyeq2solversnov2101"></a><div><img src="graphics/thyeq2solversnov2101.svg"></div></td><td nowrap="yes" align="right" valign="middle"><p class="title"><b>(14&#8211;86)</b></p></td></tr></table><p>where: </p><table border="0" summary="Simple list" class="simplelist"><tr><td>[L] = lower triangular matrix</td></tr><tr><td>[U] = upper triangular matrix</td></tr></table><p>
</p><p>By substituting: </p><table width="100%" class="equation"><colgroup><col width="95%" align="center"><col width="5%" align="right"></colgroup><tr><td align="center"><a name="thyeq3solversnov2101"></a><div><img src="graphics/thyeq3solversnov2101.svg"></div></td><td nowrap="yes" align="right" valign="middle"><p class="title"><b>(14&#8211;87)</b></p></td></tr></table><p>we can obtain {u} by first solving the triangular matrix system
for {w} by using the forward pass operation given by: </p><table width="100%" class="equation"><colgroup><col width="95%" align="center"><col width="5%" align="right"></colgroup><tr><td align="center"><a name="thyeq4solversnov2101"></a><div><img src="graphics/thyeq4solversnov2101.svg"></div></td><td nowrap="yes" align="right" valign="middle"><p class="title"><b>(14&#8211;88)</b></p></td></tr></table><p>and then computing {u} using the back substitution operation
on a triangular matrix given by: </p><table width="100%" class="equation"><colgroup><col width="95%" align="center"><col width="5%" align="right"></colgroup><tr><td align="center"><a name="thyeq5solversnov2101"></a><div><img src="graphics/thyeq5solversnov2101.svg"></div></td><td nowrap="yes" align="right" valign="middle"><p class="title"><b>(14&#8211;89)</b></p></td></tr></table><p>When [K] is symmetric, the above procedure could use the substitution: </p><table width="100%" class="equation"><colgroup><col width="95%" align="center"><col width="5%" align="right"></colgroup><tr><td align="center"><a name="thyeq6solversnov2101"></a><div><img src="graphics/thyeq6solversnov2101.svg"></div></td><td nowrap="yes" align="right" valign="middle"><p class="title"><b>(14&#8211;90)</b></p></td></tr></table><p>However, it is modified as: </p><table width="100%" class="equation"><colgroup><col width="95%" align="center"><col width="5%" align="right"></colgroup><tr><td align="center"><a name="thyeq7solversnov2101"></a><div><img src="graphics/thyeq7solversnov2101.svg"></div></td><td nowrap="yes" align="right" valign="middle"><p class="title"><b>(14&#8211;91)</b></p></td></tr></table><p>where: </p><table border="0" summary="Simple list" class="simplelist"><tr><td>[D] = a diagonal matrix </td></tr></table><p>
</p><p>The diagonal terms of [D] may be negative in the case of some
nonlinear finite element analysis. This allows the generation of [L']
without the consideration of a square root of negative number. Therefore, <a class="xref" href="thy_tool8.html#thyeq2solversnov2101" title="(14&#8211;86)">Equation&nbsp;14&#8211;86</a> through <a class="xref" href="thy_tool8.html#thyeq5solversnov2101" title="(14&#8211;89)">Equation&nbsp;14&#8211;89</a> become: </p><table width="100%" class="equation"><colgroup><col width="95%" align="center"><col width="5%" align="right"></colgroup><tr><td align="center"><a name="thyeq8solversnov2101"></a><div><img src="graphics/thyeq8solversnov2101.svg"></div></td><td nowrap="yes" align="right" valign="middle"><p class="title"><b>(14&#8211;92)</b></p></td></tr></table><table width="100%" class="equation"><colgroup><col width="95%" align="center"><col width="5%" align="right"></colgroup><tr><td align="center"><a name="thyeq9solversnov2101"></a><div><img src="graphics/thyeq9solversnov2101.svg"></div></td><td nowrap="yes" align="right" valign="middle"><p class="title"><b>(14&#8211;93)</b></p></td></tr></table><table width="100%" class="equation"><colgroup><col width="95%" align="center"><col width="5%" align="right"></colgroup><tr><td align="center"><a name="thyeq10solversnov2101"></a><div><img src="graphics/thyeq10solversnov2101.svg"></div></td><td nowrap="yes" align="right" valign="middle"><p class="title"><b>(14&#8211;94)</b></p></td></tr></table><p>and </p><table width="100%" class="equation"><colgroup><col width="95%" align="center"><col width="5%" align="right"></colgroup><tr><td align="center"><a name="thyeq11solversnov2101"></a><div><img src="graphics/thyeq11solversnov2101.svg"></div></td><td nowrap="yes" align="right" valign="middle"><p class="title"><b>(14&#8211;95)</b></p></td></tr></table><p>Since [K] is normally sparsely populated with coefficients dominantly
located around the main diagonal, the Sparse Direct Solver is designed
to handle only the nonzero entries in [K]. In general, during the
Cholesky decomposition of [K] shown in <a class="xref" href="thy_tool8.html#thyeq2solversnov2101" title="(14&#8211;86)">Equation&nbsp;14&#8211;86</a> or <a class="xref" href="thy_tool8.html#thyeq8solversnov2101" title="(14&#8211;92)">Equation&nbsp;14&#8211;92</a>, nonzero coefficients appear in [L] or [L'] at coefficient locations
where [K] matrix had zero entries. The Sparse Direct Solver algorithm
minimizes this fill-in by judiciously reordering the equation numbers
in [K].</p><p>The performance of a direct solution method is greatly optimized
through the equations reordering procedure which involves relabeling
of the variables in the vector {u}. This simply amounts to permuting
the rows and columns of [K] and the rows of {F} with the objective
of minimizing fill-in. So, when the decomposition step in <a class="xref" href="thy_tool8.html#thyeq2solversnov2101" title="(14&#8211;86)">Equation&nbsp;14&#8211;86</a> or <a class="xref" href="thy_tool8.html#thyeq8solversnov2101" title="(14&#8211;92)">Equation&nbsp;14&#8211;92</a> is performed on the reordered [K] matrix, the fill-in that occurs
in [L] or [L'] matrix is kept to a minimum. This enormously contributes
to optimizing the performance of the Sparse Direct Solver.</p><p>To achieve minimum fill-in, different matrix coefficient reordering
algorithms are available in the literature (George and Liu(<a class="xref" href="thy_biblio.html#qWJBw6djjw" title="Computer Solution of Large Sparse Positive Definite Systems">[303]</a>)). The Sparse Direct Solver uses two different
reordering schemes. They are the Minimum Degree ordering and the METIS
ordering. The choice of which reordering method to use is automated
in the solver algorithm in order to yield the least fill-in.</p></div><div class="sect2" title="14.7.3.&nbsp;Iterative Solver"><div class="titlepage"><div><div><h3 class="title"><a name="eltiterative"></a>14.7.3.&nbsp;Iterative Solver</h3></div></div></div><a class="indexterm" name="d0e68759"></a><a class="indexterm" name="d0e68762"></a><a class="indexterm" name="d0e68767"></a><a class="indexterm" name="d0e68770"></a><a class="indexterm" name="d0e68775"></a><a class="indexterm" name="d0e68778"></a><a class="indexterm" name="d0e68783"></a><a class="indexterm" name="d0e68786"></a><p>The ANSYS program offers a large number of iterative solvers
as alternatives to the direct solvers (sparse solver). These alternatives
in many cases can result in less I/O or disk usage, less total elapsed
time, and more scalable parallel performance. However, in general,
iterative solvers are not as robust as the direct solvers. For numerical
challenges such as a nearly-singular matrix (matrix with small pivots)
or a matrix that includes Lagrangian multipliers, the direct solver
is an effective solution tool, while an iterative solver is less effective
or may even fail.</p><p>The first three iterative solvers are based on the conjugate gradient
   (CG) method. The first of these three CG solvers is the Jacobi Conjugate Gradient (JCG) solver
   (Mahinthakumar and Hoole (<a class="xref" href="thy_biblio.html#c1Jjf8cmlg" title="&#34;A Parallelized Element by Element Jacobi Conjugate Gradients Algorithm for Field Problems and a Comparison with Other Schemes&#34;">[144]</a>)) (accessed with
   <a href="../ans_cmd/Hlp_C_EQSLV.html" class="olink"><span class="command"><strong>EQSLV</strong></span></a>,JCG) which is suitable for well-conditioned problems. Well-conditioned
   problems often arise from heat transfer, acoustics, magnetics and solid 2-D / 3-D structural
   analyses. The JCG solver is available for real and complex, symmetric and unsymmetric matrices.
   The second solver is the Preconditioned Conjugate Gradient (PCG) solver (accessed with
    <a href="../ans_cmd/Hlp_C_EQSLV.html" class="olink"><span class="command"><strong>EQSLV</strong></span></a>,PCG) which is efficient and reliable for all types of analyses
   including the ill-conditioned beam/shell structural analysis. The PCG solver is made available
   through a license from Computational Applications and System Integration, Inc. of Champaign,
   Illinois (USA). The PCG solver is  valid for real symmetric and unsymmetric matrices. The third
   solver is the Incomplete Cholesky Conjugate Gradient (ICCG) solver (internally developed,
   unpublished work) (accessed with <a href="../ans_cmd/Hlp_C_EQSLV.html" class="olink"><span class="command"><strong>EQSLV</strong></span></a>,ICCG). The ICCG solver is more robust
   than the JCG solver for handling ill-conditioned matrices. The ICCG solver is available for real
   and complex, symmetric and unsymmetric matrices. </p><p>The typical system of equations to be solved iteratively is
given as : </p><table width="100%" class="equation"><colgroup><col width="95%" align="center"><col width="5%" align="right"></colgroup><tr><td align="center"><a name="thyeq1iterativenov2101"></a><div><img src="graphics/thyeq1iterativenov2101.svg"></div></td><td nowrap="yes" align="right" valign="middle"><p class="title"><b>(14&#8211;96)</b></p></td></tr></table><p>where: </p><table border="0" summary="Simple list" class="simplelist"><tr><td>[K] = global coefficient matrix </td></tr><tr><td>{u} = unknown vector </td></tr><tr><td>{F} = global load vector </td></tr></table><p>
</p><p>In the CG method, the solution is found as a series of vectors
{p<sub>i</sub>}: </p><table width="100%" class="equation"><colgroup><col width="95%" align="center"><col width="5%" align="right"></colgroup><tr><td align="center"><a name="thyeq2iterativenov2101"></a><div><img src="graphics/thyeq2iterativenov2101.svg"></div></td><td nowrap="yes" align="right" valign="middle"><p class="title"><b>(14&#8211;97)</b></p></td></tr></table><p>where m is no larger than the matrix size n. The scheme is guaranteed
to converge in n or fewer iterations on an infinite precision machine.
However, since the scheme is implemented on a machine with finite
precision, it sometimes requires more than n iterations to converge.
The solvers allow up to a maximum of 2n iterations. If it still does
not converge after the 2n iterations, the solution will be abandoned
with an error message. The unconverged situation is often due to an
inadequate number of boundary constraints being used (rigid body motion).
The rate of convergence of the CG algorithm is proportional to the
square root of the conditioning number of [K] where the condition
number of [K] is equal to the ratio of the maximum eigenvalue of [K]
to the minimum eigenvalue of [K] . A preconditioning procedure is
used to reduce the condition number of linear <a class="xref" href="thy_tool8.html#thyeq1iterativenov2101" title="(14&#8211;96)">Equation&nbsp;14&#8211;96</a>. In the JCG algorithm, the diagonal
terms of [K] are used as the preconditioner [Q], while in the ICCG
and PCG algorithms, a more sophisticated preconditioner [Q] is used.
The CG algorithm with preconditioning is shown collectively as <a class="xref" href="thy_tool8.html#cgalgorithm" title="(14&#8211;98)">Equation&nbsp;14&#8211;98</a>. </p><table width="100%" class="equation"><colgroup><col width="95%" align="center"><col width="5%" align="right"></colgroup><tr><td align="center"><a name="cgalgorithm"></a><div><img src="graphics/cgalgorithm.svg"></div></td><td nowrap="yes" align="right" valign="middle"><p class="title"><b>(14&#8211;98)</b></p></td></tr></table><p>Convergence is achieved when: </p><table width="100%" class="equation"><colgroup><col width="95%" align="center"><col width="5%" align="right"></colgroup><tr><td align="center"><a name="eq35554e43-d6f7-4e61-bc40-c713ccc7eb67"></a><div><img src="graphics/eq35554e43-d6f7-4e61-bc40-c713ccc7eb67.svg"></div></td><td nowrap="yes" align="right" valign="middle"><p class="title"><b>(14&#8211;99)</b></p></td></tr></table><p>where: </p><table border="0" summary="Simple list" class="simplelist"><tr><td>&#949; = user supplied tolerance (<span class="italic"><em>TOLER</em></span> on the <a href="../ans_cmd/Hlp_C_EQSLV.html" class="olink"><span class="command"><strong>EQSLV</strong></span></a> command; output
as SPECIFIED TOLERANCE) </td></tr><tr><td>{R<sub>i</sub>} = {F} - [K] {u<sub>i</sub>} </td></tr><tr><td>{u<sub>i</sub>} = solution vector at iteration
i </td></tr></table><p>
</p><p>also, for the JCG and ICCG solvers: </p><table width="100%" class="equation"><colgroup><col width="95%" align="center"><col width="5%" align="right"></colgroup><tr><td align="center"><a name="eq63de689d-9de3-412e-b51f-f69e0f9031f8"></a><div><img src="graphics/eq63de689d-9de3-412e-b51f-f69e0f9031f8.svg"></div></td><td nowrap="yes" align="right" valign="middle"><p class="title"><b>(14&#8211;100)</b></p></td></tr></table><table width="100%" class="equation"><colgroup><col width="95%" align="center"><col width="5%" align="right"></colgroup><tr><td align="center"><a name="eq464eb6bb-fd2e-4e26-bc92-38d0e6628891"></a><div><img src="graphics/eq464eb6bb-fd2e-4e26-bc92-38d0e6628891.svg"></div></td><td nowrap="yes" align="right" valign="middle"><p class="title"><b>(14&#8211;101)</b></p></td></tr></table><p>It is assumed that the initial starting vector {u<sub>0</sub>} is a zero vector. </p></div></div><hr><p class="legalfooter"><small><i>Release 18.2 - &copy; ANSYS, Inc. All rights reserved.</i></small></p></body></html>